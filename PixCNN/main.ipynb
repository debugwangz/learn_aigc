{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-08T05:03:56.077082Z",
     "start_time": "2025-06-08T05:03:54.359259Z"
    }
   },
   "source": [
    "from scipy.io import loadmat\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import functional as F\n",
    "from pixcnn import *"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T05:03:56.298402Z",
     "start_time": "2025-06-08T05:03:56.089696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set the seed\n",
    "set_seed(42)"
   ],
   "id": "854c666e2194d99b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T05:03:56.716261Z",
     "start_time": "2025-06-08T05:03:56.481619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mnist = loadmat(\"../mnist-original.mat/mnist-original.mat\")\n",
    "mnist_data = mnist[\"data\"].T\n",
    "mnist_label = mnist[\"label\"][0]"
   ],
   "id": "ead7b9a06567ed04",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T05:03:56.733054Z",
     "start_time": "2025-06-08T05:03:56.730707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchvision import transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x.reshape(28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Pad((2, 2, 2, 2))  # Pad to 32x32\n",
    "])"
   ],
   "id": "857b8fe60ade8913",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T05:03:56.779417Z",
     "start_time": "2025-06-08T05:03:56.776502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, data, label, transform=None):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.data[idx]), self.label[idx]"
   ],
   "id": "5c06199900bd446",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T05:03:56.826168Z",
     "start_time": "2025-06-08T05:03:56.823926Z"
    }
   },
   "cell_type": "code",
   "source": "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
   "id": "8ef3fa9b14698f20",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T05:03:56.879439Z",
     "start_time": "2025-06-08T05:03:56.877213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EPOCHS = 100\n",
    "batch_size = 64\n",
    "num_workers = 8\n",
    "lr = 5e-4"
   ],
   "id": "79f934204f484c1a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T05:03:59.539743Z",
     "start_time": "2025-06-08T05:03:56.945029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "run =  wandb.init(\n",
    "    project=\"debugzwang-none\",\n",
    "    # entity=\"mnist_diffusion\",\n",
    "    name=\"pixcnn\",\n",
    "    config={\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"num_workers\": num_workers,\n",
    "        \"lr\": lr,\n",
    "    }\n",
    ")"
   ],
   "id": "2b176ed9c3c03a90",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mdebugzwang\u001B[0m (\u001B[33mdebugzwang-none\u001B[0m) to \u001B[32mhttps://api.wandb.ai\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/mnt/d/learn_aigc/PixCNN/wandb/run-20250608_130358-ufiumevb</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/debugzwang-none/debugzwang-none/runs/ufiumevb' target=\"_blank\">pixcnn</a></strong> to <a href='https://wandb.ai/debugzwang-none/debugzwang-none' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/debugzwang-none/debugzwang-none' target=\"_blank\">https://wandb.ai/debugzwang-none/debugzwang-none</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/debugzwang-none/debugzwang-none/runs/ufiumevb' target=\"_blank\">https://wandb.ai/debugzwang-none/debugzwang-none/runs/ufiumevb</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T05:03:59.710216Z",
     "start_time": "2025-06-08T05:03:59.567674Z"
    }
   },
   "cell_type": "code",
   "source": "model = PixelCNN().to(device)\n",
   "id": "e02235501fdd5ff",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T05:04:14.988459Z",
     "start_time": "2025-06-08T05:04:14.983184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def loss_function(logits, images):\n",
    "    loss = F.binary_cross_entropy_with_logits(logits, images)\n",
    "    return loss\n",
    "def train(\n",
    "        model: PixelCNN,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        epochs: int,\n",
    "        device: str,\n",
    "        train_dataloader: DataLoader,\n",
    "        val_dataloader: DataLoader,\n",
    "):\n",
    "    # training_losses = []\n",
    "    # val_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for index, (imgs, labels) in enumerate(val_dataloader):\n",
    "                imgs = (imgs > 0.33).float() # convert to 0, 1\n",
    "                imgs = imgs.to(device)\n",
    "                logits = model(imgs)\n",
    "                loss = loss_function(logits, imgs)    \n",
    "                val_loss += loss.item()\n",
    "                if index == 0 and epoch % 10 == 0:\n",
    "                    C = 1\n",
    "                    H = 32\n",
    "                    W = 32\n",
    "                    output = torch.zeros(1, C, H, W).to(device)\n",
    "                    for h in range(H):\n",
    "                        for w in range(W):\n",
    "                            for c in range(C):\n",
    "                                # Feed the whole array and retrieving the pixel value probabilities for the next pixel.\n",
    "                                logits = model(output)[:, c, h, w]\n",
    "                                probs = logits.sigmoid()\n",
    "                                # Use the probabilities to pick pixel values and append the values to the image frame.\n",
    "                                output[:, c, h, w] = torch.bernoulli(probs)\n",
    "                    images = [wandb.Image(output[i].squeeze(0).cpu().numpy()) for i in range(1)]\n",
    "                    wandb.log({\"batch_images\": images})\n",
    "        model.train(True)\n",
    "        training_loss = 0\n",
    "\n",
    "        for index, (imgs, labels) in enumerate(train_dataloader):\n",
    "            imgs = (imgs > 0.33).float() # convert to 0, 1\n",
    "            imgs = imgs.to(device)\n",
    "            logits = model(imgs)\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_function(logits, imgs)    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.item()\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"training_loss\": training_loss / len(train_dataloader),\n",
    "            \"val_loss\": val_loss / len(val_dataloader),\n",
    "        })\n",
    "    # return training_losses, val_losses"
   ],
   "id": "658e752a02030941",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T05:04:15.218884Z",
     "start_time": "2025-06-08T05:04:15.210874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# Assuming mnist_data and mnist_label are already defined\n",
    "dataset = MNISTDataset(mnist_data, mnist_label, transform=transform)\n",
    "\n",
    "# Define the lengths for training and validation sets\n",
    "train_size = 50000\n",
    "val_size = 10000\n",
    "# train_size = 500\n",
    "# val_size = 100\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Now you can use train_dataset and val_dataset with DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False)"
   ],
   "id": "9cb0547368bc3225",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T05:34:13.076625Z",
     "start_time": "2025-06-08T05:04:15.796638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train(\n",
    "    model=model,\n",
    "    optimizer=torch.optim.Adam(params=model.parameters(), lr=lr),\n",
    "    epochs=EPOCHS,\n",
    "    device=device,\n",
    "    train_dataloader=train_loader,\n",
    "    val_dataloader=val_loader,\n",
    ")"
   ],
   "id": "323073fbb2c1269e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "Epoch 3/100\n",
      "Epoch 4/100\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "Epoch 7/100\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "Epoch 12/100\n",
      "Epoch 13/100\n",
      "Epoch 14/100\n",
      "Epoch 15/100\n",
      "Epoch 16/100\n",
      "Epoch 17/100\n",
      "Epoch 18/100\n",
      "Epoch 19/100\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "Epoch 22/100\n",
      "Epoch 23/100\n",
      "Epoch 24/100\n",
      "Epoch 25/100\n",
      "Epoch 26/100\n",
      "Epoch 27/100\n",
      "Epoch 28/100\n",
      "Epoch 29/100\n",
      "Epoch 30/100\n",
      "Epoch 31/100\n",
      "Epoch 32/100\n",
      "Epoch 33/100\n",
      "Epoch 34/100\n",
      "Epoch 35/100\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n",
      "Epoch 38/100\n",
      "Epoch 39/100\n",
      "Epoch 40/100\n",
      "Epoch 41/100\n",
      "Epoch 42/100\n",
      "Epoch 43/100\n",
      "Epoch 44/100\n",
      "Epoch 45/100\n",
      "Epoch 46/100\n",
      "Epoch 47/100\n",
      "Epoch 48/100\n",
      "Epoch 49/100\n",
      "Epoch 50/100\n",
      "Epoch 51/100\n",
      "Epoch 52/100\n",
      "Epoch 53/100\n",
      "Epoch 54/100\n",
      "Epoch 55/100\n",
      "Epoch 56/100\n",
      "Epoch 57/100\n",
      "Epoch 58/100\n",
      "Epoch 59/100\n",
      "Epoch 60/100\n",
      "Epoch 61/100\n",
      "Epoch 62/100\n",
      "Epoch 63/100\n",
      "Epoch 64/100\n",
      "Epoch 65/100\n",
      "Epoch 66/100\n",
      "Epoch 67/100\n",
      "Epoch 68/100\n",
      "Epoch 69/100\n",
      "Epoch 70/100\n",
      "Epoch 71/100\n",
      "Epoch 72/100\n",
      "Epoch 73/100\n",
      "Epoch 74/100\n",
      "Epoch 75/100\n",
      "Epoch 76/100\n",
      "Epoch 77/100\n",
      "Epoch 78/100\n",
      "Epoch 79/100\n",
      "Epoch 80/100\n",
      "Epoch 81/100\n",
      "Epoch 82/100\n",
      "Epoch 83/100\n",
      "Epoch 84/100\n",
      "Epoch 85/100\n",
      "Epoch 86/100\n",
      "Epoch 87/100\n",
      "Epoch 88/100\n",
      "Epoch 89/100\n",
      "Epoch 90/100\n",
      "Epoch 91/100\n",
      "Epoch 92/100\n",
      "Epoch 93/100\n",
      "Epoch 94/100\n",
      "Epoch 95/100\n",
      "Epoch 96/100\n",
      "Epoch 97/100\n",
      "Epoch 98/100\n",
      "Epoch 99/100\n",
      "Epoch 100/100\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T05:34:13.088174Z",
     "start_time": "2025-06-08T05:34:13.082305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def show_images(images):\n",
    "    grid = vutils.make_grid(images, nrow=4, padding=2, normalize=True)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(grid.permute(1, 2, 0).cpu(), cmap='gray')  # 调整维度顺序\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    plt.close()"
   ],
   "id": "181c7d278fd1e09",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T05:34:14.382856Z",
     "start_time": "2025-06-08T05:34:13.185445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "C = 1\n",
    "H = 32\n",
    "W = 32\n",
    "output = torch.zeros(16, C, H, W).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for h in range(H):\n",
    "        for w in range(W):\n",
    "            for c in range(C):\n",
    "                # Feed the whole array and retrieving the pixel value probabilities for the next pixel.\n",
    "                logits = model(output)[:, c, h, w]\n",
    "                probs = logits.sigmoid()\n",
    "                # Use the probabilities to pick pixel values and append the values to the image frame.\n",
    "                output[:, c, h, w] = torch.bernoulli(probs)\n",
    "    show_images(output)\n"
   ],
   "id": "49c5b245d71b3e1c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T05:51:41.461678Z",
     "start_time": "2025-06-08T05:51:41.427443Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(model.state_dict(), f\"/mnt/d/data/mnist_model/pixcnn_lr_{lr}_epoch_{EPOCHS}.pth\")",
   "id": "5a025bfc5ef40392",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T14:03:24.298131Z",
     "start_time": "2025-02-27T14:03:24.296327Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2c02ee4b8ab933fb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
